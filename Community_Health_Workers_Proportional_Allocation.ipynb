{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suzan Iloglu, May 21,2020\n",
    "# Import packages\n",
    "import csv\n",
    "import gurobipy as gp\n",
    "from itertools import product\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns =200\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING THE NEW POLITICS OF CARE: COMMUNITY HEALTH WORKERS\n",
    "The project presents multiple options for how individual workers in such a Community Health Corps might be distributed within each state. It shows that what you choose to prioritize greatly impacts where care would be sent. We can define communities in greatest need in many ways: we can think about our current crisis and send people to where the COVID19 pandemic rages most fiercely; we can think of long term measures of social and economic inequality embedded in metrics like the Centers for Disease Control and Prevention’s Social Vulnerability Index; we can focus on the places with too many people dying too young and use the County Health Rankings Years-of-Potential-Life-Lost measure; we can think of joblessness and how the pandemic has thrown many into unemployment and target our resources in this way. \n",
    "\n",
    "The followings are our options to choose to define vulnerability:\n",
    "\n",
    "\n",
    "- SOCIAL VULNERABILITY INDEX\n",
    "- MEDICAID \n",
    "- UNEMPLOYMENT\n",
    "- YEARS OF POTENTIAL LIFE LOST\n",
    "- TOTAL COVID CASES\n",
    "- COVID CASES BY POPULATION\n",
    "- COVID DEATHS BY POPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with Social Vulnerability Index (SVI) from CDC website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Importing SVI data which includes the variables for calculating county SVI for each state\n",
    "The CDC uses both a USA-wide and a state by state SVI scores. For our project given that funding is likely going to be managed at a state level, using a state by state SVI scores makes the most sense and will be most sensitive to regional socioeconomic differences. Even though the CDC SVI scores are calculated using percentile rankings, the data sets include raw data estimates for each variables. The following table shows the variablaes used in the method of calculating SVI scores. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      American Community Survey (ACS), 2014-2018 (5-year) data for the following estimates:\n",
    "<img src=\"Data/img/SVI_comp.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Note: Full documentation for 2018 data is available <a href=\"https://svi.cdc.gov/data-and-tools-download.html\">here</a> \n",
    "This part of the code shows preliminary mapping of <a href = \"https://svi.cdc.gov/\">the CDC's Social Vulnerability Index</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in the notebook, we will provide the formula to create the SVI value we use in our project. First, we import the data for the US mainland and Puerto Rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import svi data downloaded from CDC website as cited above\n",
    "\n",
    "## 48 state SVI scores by county\n",
    "svi_counties_mainland = gpd.read_file(\"Data/SVI2018_US_COUNTY/SVI2018_US_county.shp\")\n",
    "\n",
    "## Puerto Rico SVI scores by county\n",
    "svi_counties_puerto_rico = gpd.read_file(\"Data/PuertoRico_COUNTY/SVI2018_PuertoRico_county.shp\")\n",
    "\n",
    "## Merge 48 states and Puerto Rico SVI \n",
    "svi_counties = pd.concat([svi_counties_mainland,svi_counties_puerto_rico ], sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing -999 values with 0 for calculations\n",
    "svi_county = svi_counties.fillna(0)\n",
    "svi_county  = svi_county.replace(-999, 0)\n",
    "svi_county['FIPS'] = svi_county['FIPS'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the list for State\n",
    "State = svi_county.STATE.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate dictionary for the variables to calculate SVI\n",
    "\n",
    "# Persons below poverty estimate, 2014-2018 ACS\n",
    "E_POV = dict(zip(svi_county.FIPS, svi_county.E_POV))\n",
    "\n",
    "# Civilian (age 16+) unemployed estimate, 2014-2018 ACS\n",
    "E_UNEMP = dict(zip(svi_county.FIPS, svi_county.E_UNEMP))\n",
    "\n",
    "# Per capita income estimate, 2014-2018 ACS\n",
    "E_PCI = dict(zip(svi_county.FIPS, svi_county.E_PCI))\n",
    "\n",
    "# Persons (age 25+) with no high school diploma estimate, 2014-2018 ACS\n",
    "E_NOHSDP = dict(zip(svi_county.FIPS, svi_county.E_NOHSDP))\n",
    "\n",
    "# Persons aged 65 and older estimate\n",
    "E_AGE65 = dict(zip(svi_county.FIPS, svi_county.E_AGE65))\n",
    "\n",
    "# Persons aged 17 and younger estimate\n",
    "E_AGE17 = dict(zip(svi_county.FIPS, svi_county.E_AGE17))\n",
    "\n",
    "# Population with a disability estimate\n",
    "E_DISABL = dict(zip(svi_county.FIPS, svi_county.E_DISABL))\n",
    "\n",
    "# Single parent households with children under 18 estimate\n",
    "E_SNGPNT = dict(zip(svi_county.FIPS, svi_county.E_SNGPNT))\n",
    "\n",
    "# Minority (all persons except white, nonHispanic) estimate, 2014-2018 ACS\n",
    "E_MINRTY = dict(zip(svi_county.FIPS, svi_county.E_MINRTY))\n",
    "\n",
    "# Persons (age 5+) who speak English \"less than well\" estimate, 2014-2018 ACS\n",
    "E_LIMENG = dict(zip(svi_county.FIPS, svi_county.E_LIMENG))\n",
    "\n",
    "# Housing in structures with 10 or more units estimate, 2014-2018 ACS\n",
    "E_MUNIT = dict(zip(svi_county.FIPS, svi_county.E_MUNIT))\n",
    "\n",
    "# Mobile homes estimate MOE, 2014-2018 ACS\n",
    "E_MOBILE = dict(zip(svi_county.FIPS, svi_county.E_MOBILE))\n",
    "\n",
    "# At household level (occupied housing units), more people than rooms estimate, 2014-2018 ACS\n",
    "E_CROWD = dict(zip(svi_county.FIPS, svi_county.E_CROWD))\n",
    "\n",
    "# Households with no vehicle available estimate, 2014-2018 ACS\n",
    "E_NOVEH = dict(zip(svi_county.FIPS, svi_county.E_NOVEH))\n",
    "\n",
    "# Persons in institutionalized group quarters estimate, 2014-2018 ACS\n",
    "E_GROUPQ = dict(zip(svi_county.FIPS, svi_county.E_GROUPQ))\n",
    "\n",
    "# Percentage of persons below poverty estimate\n",
    "E_POV = dict(zip(svi_county.FIPS, svi_county.E_POV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicaid \n",
    "Medicaid is a means-tested health insurance program for low-income children, pregnant women, adults, seniors, and people with disabilities. Medicaid is jointly funded by federal and state governments and managed by states within federal standards and a wide range of state options. <a href=\"https://data.medicaid.gov/Enrollment/State-Medicaid-and-CHIP-Applications-Eligibility-D/n5ce-jxme\"> Data Source for Medicaid Enrollment </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the medicaid demand data\n",
    "df_m = pd.read_csv(\"Data/Medicaid_Demand.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unemployment \n",
    "The unemployment rate is calculated by the U.S. Bureau of Labor Statistics as the percentage of the civilian labor force who are without jobs and have actively sought work within the past four weeks. <a href=\"https://www.bls.gov/lau/laufaq.htm#Q01\"> Data Source for Unemployment  </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Unemployment data\n",
    "df_unemp = pd.read_csv(\"Data/Unemployment.csv\")\n",
    "\n",
    "# Fill NA with 0\n",
    "df_unemp = df_unemp.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Years of Potential Life Lost (YPLL)\n",
    "\n",
    "Years of Potential Life Lost (YPLL) measures the rate of premature deaths by region. YPLL is calculated as the sum of the estimated number of years that individuals would have lived if they had not died before the age of 75 per 100,000 people. <a href=\"https://www.countyhealthrankings.org/sites/default/files/media/document/2020%20County%20Health%20Rankings%20Data%20-%20v2.xlsx\"> Data Source for YPLL.  </a> More information about YPLL can be dounf in this <a href=\"https://www.countyhealthrankings.org/explore-health-rankings/measures-data-sources/county-health-rankings-model/health-outcomes/length-of-life/premature-death-ypll\"> link. </a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the YPLL data\n",
    "df_y = pd.read_csv(\"Data/YPLL.csv\")\n",
    "\n",
    "# Fill NA with the mean of the data\n",
    "df_y = df_y.fillna(df_y.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Population data\n",
    "df_pop = pd.read_csv(\"Data/County_pop_2019.csv\")\n",
    "\n",
    "# Fill NA with 0\n",
    "df_pop = df_pop.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for the county and population\n",
    "population_county = df_pop.set_index('FIPS')['pop'].to_dict()\n",
    "\n",
    "# Create a dictionary for the county and YPLL\n",
    "YPLL = dict(zip(df_y.FIPS, df_y.YPLL))\n",
    "\n",
    "# Create a dictionary for the county and Unemployment\n",
    "Unemployment = dict(zip(df_unemp.FIPS, df_unemp.Unemployed))\n",
    "\n",
    "# Create a dictionary for the county and Community Health Workers (CHW) demand\n",
    "# Note that we assume a CHW can serve 55 Medicaid patient so the demand for CHW will be\n",
    "# Medicaid patient number divided by 55\n",
    "Medicaid_demand = dict(zip(df_m.FIPS, df_m.Med_Demand/55))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Cases & COVID-19 Cases per Capita\n",
    "\n",
    "What are COVID-19 Cases and COVID-19 Cases per Capita?\n",
    "\n",
    "COVID-19 cases is an absolute metric of the total number of COVID-19 cases in a county over the last fourteen days.  COVID-19 cases per 100,000 is a relative metric calculated by dividing the number of COVID-19 cases by the estimated county population and multiplying by 100,000.  Cases include both confirmed cases, based on viral testing, and probable cases, based on specific criteria for symptoms and epidemiological exposure. We use NY Times Covid data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data with the most recent date in NY Times dataset:\n",
    "\n",
    "today = time.strftime('%Y-%m-%d')\n",
    "covid_data_update_date = today#'2020-07-21'#today #or enter a specific date such as '2020-07-06'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14 day period defined\n",
    "data_date_dt = pd.to_datetime(covid_data_update_date,infer_datetime_format = True)\n",
    "\n",
    "N = 14\n",
    "\n",
    "date_N_days_ago = data_date_dt - timedelta(days = N)\n",
    "\n",
    "date_N1_days_ago = data_date_dt - timedelta(days = N+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "\n",
    "# URL for mainland US data\n",
    "url = \"http://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "s = requests.get(url).content\n",
    "covid = pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Since NY data is seperately available, we first read the NY data for all 5 different borough then combine with the rest of US data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for NY\n",
    "url = \"https://raw.githubusercontent.com/nychealth/coronavirus-data/master/boro/boroughs-case-hosp-death.csv\"\n",
    "\n",
    "ny = requests.get(url).content\n",
    "covid_ny = pd.read_csv(io.StringIO(ny.decode('utf-8')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Kings = covid_ny[['DATE_OF_INTEREST', 'BK_CASE_COUNT']]\n",
    "Kings.rename(columns = {'BK_CASE_COUNT': 'cases', 'DATE_OF_INTEREST': 'date'} , inplace=True)\n",
    "Kings['county'] = 'Kings'\n",
    "Kings['state'] = 'New York'\n",
    "Kings['fips'] = '36047'\n",
    "#Kings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Bronx = covid_ny[['DATE_OF_INTEREST', 'BX_CASE_COUNT']]\n",
    "Bronx.rename(columns = {'BX_CASE_COUNT': 'cases', 'DATE_OF_INTEREST': 'date'} , inplace=True)\n",
    "Bronx['state'] = 'New York'\n",
    "Bronx['county'] = 'Bronx'\n",
    "Bronx['fips'] = '36005'\n",
    "#Bronx.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Manhattan = covid_ny[['DATE_OF_INTEREST', 'MN_CASE_COUNT']]\n",
    "Manhattan.rename(columns = {'MN_CASE_COUNT': 'cases', 'DATE_OF_INTEREST': 'date'} , inplace=True)\n",
    "Manhattan['state'] = 'New York'\n",
    "Manhattan['county'] = 'Manhattan'\n",
    "Manhattan['fips'] = '36061'\n",
    "#Manhattan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Queens = covid_ny[['DATE_OF_INTEREST', 'QN_CASE_COUNT']]\n",
    "Queens.rename(columns = {'QN_CASE_COUNT': 'cases', 'DATE_OF_INTEREST': 'date'} , inplace=True)\n",
    "Queens['state'] = 'New York'\n",
    "Queens['county'] = 'Queens'\n",
    "Queens['fips'] = '36081'\n",
    "#Queens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Richmond = covid_ny[['DATE_OF_INTEREST', 'SI_CASE_COUNT']]\n",
    "Richmond.rename(columns = {'SI_CASE_COUNT': 'cases', 'DATE_OF_INTEREST': 'date'} , inplace=True)\n",
    "Richmond['state'] = 'New York'\n",
    "Richmond['county'] = 'Richmond'\n",
    "Richmond['fips'] = '36085'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge the NY data with the rest of the US data\n",
    "covid = pd.concat([covid, Kings, Bronx, Manhattan, Queens, Richmond], sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid['dt'] = pd.to_datetime(covid['date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset last last 15 days\n",
    "covid_last15 = covid[(covid['dt']>date_N1_days_ago) & (covid['dt']<= data_date_dt)].copy()\n",
    "covid_last15['dt_time_delta'] = covid_last15['dt']-data_date_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate new daily cases\n",
    "\n",
    "## sort values by county and date\n",
    "covid_last15.sort_values(by=['fips','dt'],inplace=True)\n",
    "## remove data with 'unknown' counties\n",
    "covid_last15 = covid_last15[covid_last15['fips'].notnull()].copy()\n",
    "\n",
    "## calculate daily difference in number of cases\n",
    "covid_last15['new_cases'] = covid_last15.groupby('fips')['cases'].transform(lambda x: x.diff())\n",
    "## set negative new cases to zero, this can occuer due to the disperacy in the data\n",
    "\n",
    "covid_last15.loc[covid_last15.new_cases < 1e-6, 'new_cases'] = 0\n",
    "covid_last15.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select just last 14 days now that we have daily new cases with 15th day as baseline\n",
    "covid_last14 = covid_last15[(covid_last15['dt'] > date_N_days_ago) & (covid_last15['dt'] <= data_date_dt)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by to get case load and follow up demand values for each county\n",
    "covid_last14_stats = covid_last14.groupby(['fips'])['new_cases','deaths'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding population information from CDC svi dataset\n",
    "covid_last14_stats = covid_last14_stats.reset_index()\n",
    "covid_last14_stats['fips'] = covid_last14_stats['fips'].astype(int)\n",
    "svi_county['FIPS'] = svi_county['FIPS'].astype(int)\n",
    "covid_last14_stats = pd.merge(left = covid_last14_stats, right = svi_county[['E_TOTPOP','FIPS', 'STATE']], how = 'right', right_on = 'FIPS', left_on = 'fips' )\n",
    "covid_last14_stats.fillna(0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for the cumulative COVID deaths in each county\n",
    "County_covid_death = dict(zip(covid_last14_stats.FIPS, covid_last14_stats.deaths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary for the states of the given the county FIPS\n",
    "county_of_states = dict(zip(svi_county.FIPS, svi_county.STATE))\n",
    "\n",
    "# Create a dictionary for the name of the given the county FIPS\n",
    "county_name = dict(zip(svi_county.FIPS, svi_county.COUNTY))\n",
    "\n",
    "# Create the list for county FIPS, we consider counties as analogy to the center for community health workers\n",
    "location = svi_county.FIPS.tolist() #[k for k in SVI_county] #[9001, 9003, 9005, 9007, 9009, 9011, 9013, 9015]#[k for k in SVI_county]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for the county and covid cases\n",
    "covid_cases_county_ny_times = dict(zip(covid_last14_stats.fips, covid_last14_stats.new_cases))\n",
    "COVID_14days = {}\n",
    "\n",
    "for j in location:\n",
    "    if j in covid_cases_county_ny_times:\n",
    "        COVID_14days[j] = covid_cases_county_ny_times[j]   \n",
    "    else:\n",
    "        COVID_14days[j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "pro_c_s = [(i,county_of_states[i]) for i in location ]\n",
    "cartesian_pro_county_state = gp.tuplelist(pro_c_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = covid_last14_stats\n",
    "df['fips'] = df['fips'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "######################## END calculating different types of vulnerabilities ###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we allocate CHW proportional to the county values of certain vulnaribilites within state, we need a few function to help us with the calculations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function return the value for the state for the given dictionary\n",
    "\n",
    "# More specifically sum upt the values for the counties of each state\n",
    "\n",
    "def total_state(dict_1):\n",
    "    state_dict = {}\n",
    "    for s in State:\n",
    "        state_dict [s] = sum(dict_1[j] for (j,s) in cartesian_pro_county_state.select('*', s))  \n",
    "    return state_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function return the value for the state for the given dictionary\n",
    "\n",
    "# More specifically sum upt the values for the counties of each state\n",
    "\n",
    "#def total_state_bypop(dict_1):\n",
    " #   state_dict = {}\n",
    "  #  for s in State:\n",
    "   #     state_dict [s] = sum(dict_1[j]/population_county[j] for (j,s) in cartesian_pro_county_state.select('*', s))  \n",
    "    #return state_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculte the population per state by summing up the population in each county in the state\n",
    "State_pop = total_state(population_county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function returns the ratio of the dict value for county and state of the county\n",
    "def Proportional(county_level, state_level):\n",
    "    \n",
    "    prop = {}\n",
    "       \n",
    "    for (j,s) in cartesian_pro_county_state:\n",
    "        if state_level[s] >= 1e-6:\n",
    "            prop[j] = (county_level[j]/state_level[s])    \n",
    "        else:\n",
    "            prop[j] = 0\n",
    "                \n",
    "    return prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for the variables of SVI\n",
    "E_POV = dict(zip(svi_county.FIPS, svi_county.EP_POV))\n",
    "E_UNEMP = dict(zip(svi_county.FIPS, svi_county.EP_UNEMP))\n",
    "E_PCI = dict(zip(svi_county.FIPS, svi_county.EP_PCI))\n",
    "E_NOHSDP = dict(zip(svi_county.FIPS, svi_county.EP_NOHSDP))\n",
    "E_AGE65 = dict(zip(svi_county.FIPS, svi_county.EP_AGE65))\n",
    "E_AGE17 = dict(zip(svi_county.FIPS, svi_county.EP_AGE17))\n",
    "E_DISABL = dict(zip(svi_county.FIPS, svi_county.EP_DISABL))\n",
    "E_SNGPNT = dict(zip(svi_county.FIPS, svi_county.EP_SNGPNT))\n",
    "E_MINRTY = dict(zip(svi_county.FIPS, svi_county.EP_MINRTY))\n",
    "E_LIMENG = dict(zip(svi_county.FIPS, svi_county.EP_LIMENG))\n",
    "E_MUNIT = dict(zip(svi_county.FIPS, svi_county.EP_MUNIT))\n",
    "E_MOBILE = dict(zip(svi_county.FIPS, svi_county.EP_MOBILE))\n",
    "E_CROWD = dict(zip(svi_county.FIPS, svi_county.EP_CROWD))\n",
    "E_NOVEH = dict(zip(svi_county.FIPS, svi_county.EP_NOVEH))\n",
    "E_GROUPQ = dict(zip(svi_county.FIPS, svi_county.EP_GROUPQ))\n",
    "\n",
    "\n",
    "# Calculate the state value for the SVI variables\n",
    "E_POV_State = total_state(E_POV)\n",
    "E_UNEMP_State = total_state(E_UNEMP) \n",
    "E_PCI_State = total_state(E_PCI)\n",
    "E_NOHSDP_State = total_state(E_NOHSDP) \n",
    "E_AGE65_State = total_state(E_AGE65)\n",
    "E_AGE17_State = total_state(E_AGE17)\n",
    "E_DISABL_State = total_state(E_DISABL)\n",
    "E_SNGPNT_State = total_state(E_SNGPNT)\n",
    "E_MINRTY_State = total_state(E_MINRTY)\n",
    "E_LIMENG_State = total_state(E_LIMENG)\n",
    "E_MUNIT_State = total_state(E_MUNIT)\n",
    "E_MOBILE_State = total_state(E_MOBILE)\n",
    "E_CROWD_State = total_state(E_CROWD)\n",
    "E_NOVEH_State = total_state(E_NOVEH)\n",
    "E_GROUPQ_State = total_state(E_GROUPQ)\n",
    "\n",
    "\n",
    "# Calculate the proportinal values for the SVI variables\n",
    "E_POV_Prop = Proportional(E_POV, E_POV_State )\n",
    "E_UNEMP_Prop = Proportional(E_UNEMP, E_UNEMP_State ) \n",
    "E_PCI_Prop = Proportional(E_PCI, E_PCI_State )\n",
    "E_NOHSDP_Prop = Proportional(E_NOHSDP, E_NOHSDP_State ) \n",
    "E_AGE65_Prop = Proportional(E_AGE65, E_AGE65_State )\n",
    "E_AGE17_Prop = Proportional(E_AGE17, E_AGE17_State )\n",
    "E_DISABL_Prop = Proportional(E_DISABL, E_DISABL_State )\n",
    "E_SNGPNT_Prop = Proportional(E_SNGPNT, E_SNGPNT_State )\n",
    "E_MINRTY_Prop = Proportional(E_MINRTY, E_MINRTY_State )\n",
    "E_LIMENG_Prop = Proportional(E_LIMENG, E_LIMENG_State )\n",
    "E_MUNIT_Prop = Proportional(E_MUNIT, E_MUNIT_State )\n",
    "E_MOBILE_Prop = Proportional(E_MOBILE, E_MOBILE_State )\n",
    "E_CROWD_Prop = Proportional(E_CROWD, E_CROWD_State )\n",
    "E_NOVEH_Prop = Proportional(E_NOVEH, E_NOVEH_State )\n",
    "E_GROUPQ_Prop = Proportional(E_GROUPQ, E_GROUPQ_State )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI calculation \n",
    "\n",
    "We calculate the ratio of county value to state value by population for each SVI variables (we use EP-estimate percentage- values in the CDC data set), then we take the average of all 15 SVI variables. \n",
    "\n",
    "Let SVI variable set be K, where  \n",
    "\n",
    "K = { Below Poverty, Unemployed, Income, No High School Diploma, Aged 65 or Older, Aged 17 or Younger, Civilian with a Disability, Single-Parent Households, Minority, Speaks English “Less than Well”, Multi-Unit Structures, Mobile Homes, Crowding, No Vehicle, Group Quarters }\n",
    "\n",
    "We will use these variables in a county base and state base. While County base values are exactly same as the estimated values for these variables in the CDC website, to calculate the state base, we simply sum the county values for all of the counties in each state for each variable. Then we use the following formula to calculate the SVI value for each county.\n",
    "\n",
    "Let $S$ is the set of states and $j$ is a county in the state $s$, where $s \\in S$, $c^k_j$ SVI variable $k \\in K$ value for county j, and $c_s$ SVI variable value for state s.\n",
    "\n",
    "$SVI_j = \\frac{1}{15}\\sum_{k \\in K} \\frac{c^k_j}{c^k_s}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "# Sum all SVI variable values for each county\n",
    "SVI_county_sum = dict(Counter(E_POV_Prop) + Counter(E_UNEMP_Prop) + Counter(E_PCI_Prop) + Counter(E_NOHSDP_Prop) + Counter(E_AGE65_Prop) + Counter(E_AGE17_Prop) + Counter(E_DISABL_Prop) + Counter(E_SNGPNT_Prop) + Counter(E_MINRTY_Prop) + Counter(E_LIMENG_Prop) + Counter(E_MUNIT_Prop) + Counter(E_MOBILE_Prop) + Counter(E_CROWD_Prop) + Counter(E_NOVEH_Prop) + Counter(E_GROUPQ_Prop))\n",
    "\n",
    "# Divide the sum of all SVI variable values\n",
    "SVI_county = {j: SVI_county_sum[j]/15 for j in SVI_county_sum }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further we create additional vulnerability values by considering SVI, YPLL, Unemployment, COVID, COVID_capita, COVID_death and COVID_death capita and the number of Medicaid enrolles in each county together\n",
    "\n",
    "Covid_capita = {j: 100000*(COVID_14days[j]/population_county[j]) for j in location}\n",
    "\n",
    "Covid_death_capita = {j: 100000*(County_covid_death[j]/population_county[j]) for j in location}\n",
    "\n",
    "Medicaid_capita = {j: 100000*(Medicaid_demand[j]/population_county[j]) for j in location}\n",
    "\n",
    "Unemployment_capita = {j: 100000*(Unemployment[j]/population_county[j]) for j in location}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportional Allocation\n",
    "\n",
    "We consider allocating 1 million CHW over the states proportional to Medicaid enrollment in each state. Further, we allocate CHW to counties in each state proportional to different county vulnerability criterias as follow.\n",
    "\n",
    "- MEDICAID\n",
    "- SVI\n",
    "- YPLL\n",
    "- UNEMPLOYMENT\n",
    "- LAST 14 DAYS COVID CASES\n",
    "- LAST 14 DAYS COVID CASES / POP\n",
    "- COVID DEATHS / POP\n",
    "\n",
    "To calculate the total number of allocated CHW to per county according to these vulnerability criterias, we define the following function called \"Proportional_allocation\", in which we multiply the CHW allocated to each state with the ratio of the chosen vulnerability criteria of the county to the chosen vulnerability criteria of the state, the function return a dictionary with the counties as keys and the number of CHW allocated to each county for the chosen vulnerability criteria as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Proportional_allocation(county_level, state_level, state_budget):\n",
    "    prop_allocate = {}\n",
    "       \n",
    "    for (j,s) in cartesian_pro_county_state:\n",
    "        if state_level[s] >= 1e-6:\n",
    "            prop_allocate[j,s] = (county_level[j]/state_level[s])*state_budget[s]\n",
    "        \n",
    "        else:\n",
    "            prop_allocate[j,s] = 0\n",
    "            \n",
    "    \n",
    "    return prop_allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for the different vulnerability criteria values for states\n",
    "\n",
    "# Dictionary for total Medicaid patient numbers for each state\n",
    "Medicaid_demand_state = total_state(Medicaid_demand) \n",
    "\n",
    "# Dictionary for total positive COVID cases for last 14 days in each state\n",
    "Covid_state = total_state(COVID_14days) \n",
    "\n",
    "# Dictionary for total SVI values for each state\n",
    "SVI_state = total_state(SVI_county) \n",
    "\n",
    "# Dictionary for total YPLL values for each state\n",
    "YPLL_state = total_state(YPLL) \n",
    "\n",
    "# Dictionary for total Unemployment numbers for each state\n",
    "Unemployment_state = total_state(Unemployment)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for the total Covid per capita for each state\n",
    "Total_covid_cap = total_state(Covid_capita) \n",
    "\n",
    "\n",
    "# Dictionary for the total Covid death per capita for each state\n",
    "Total_covid_death_cap = total_state(Covid_death_capita) \n",
    "\n",
    "\n",
    "# Dictionary for the total Medicaid per capita for each state\n",
    "Total_medicaid_cap = total_state(Medicaid_capita)\n",
    "\n",
    "\n",
    "# Dictionary for the total Unemployment per capita for each state\n",
    "Total_unemployment_cap = total_state(Unemployment_capita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 million CHW allocation to states\n",
    "\n",
    "We allocate 1 million CHWs to states proportional to total Medicaid enrolles in each state.\n",
    "\n",
    "Let's $FedCHW$ represents the number of CHW will be allocated within states by the federal government, which is 1 million in our project. $TotMed$ represents the total Medicaid enrollee numbers over the US, $Med_s$ is the total Medicaid enrollee numbers in state $s \\in S$, and $CHW_s$ is the total number of CHW allocated to state $ s\\in S$. \n",
    "\n",
    "$CHW_s = FedCHW*\\frac{Med_s}{TotMed}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider allocation of 1 million CHW all over the US\n",
    "Federal_budget_CHW = 1000000\n",
    "\n",
    "# First, we calculate the Total Medicaid enrolles all over the US\n",
    "Total_federal_need = sum(Medicaid_demand_state[s] for s in State)\n",
    "\n",
    "# Allocate the 1 million CHWs proportional to Medicaid enrolles in each state\n",
    "for s in State:\n",
    "    Medicaid_budget_state[s] = (Medicaid_demand_state[s]/Total_federal_need)*Federal_budget_CHW  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportional allocation for different vulnerability values\n",
    "\n",
    "Let V = {Medicaid, SVI, YPLL, Unemployment, COVID, COVID_capita, COVID_death and COVID_death capita, SVI and Medicaid, YPLL and Medicaid, Unemployment and Medicaid, COVID and Medicaid, COVID_capita and Medicaid, COVID_death and Medicaid and COVID_death capita and Medicaid}. We assume $v_j$ represent the vulnerability value for county $j \\in J$, while $v_s$ represent the sum of the vulnerability values for each county in the state of county j.\n",
    "\n",
    "$Prop_{v_j} = \\frac{v_j}{v_s}*CHW_s$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling proportional allocation function for different vulnerability criterias\n",
    "\n",
    "# Proportional allocation according to cumulative Covid death in per capita in each county\n",
    "Proportional_to_covid_death_cap = Proportional_allocation(Covid_death_capita, Total_covid_death_cap,Medicaid_budget_state)\n",
    "\n",
    "# Propportional allocation according to Medicaid enrollee number in each county\n",
    "Proportional_to_medicaid = Proportional_allocation(Medicaid_demand, Medicaid_demand_state,Medicaid_budget_state )\n",
    "\n",
    "# Proportional allocation according to Medicaid enrolles per capita in each county\n",
    "Proportional_to_medicaid_cap = Proportional_allocation(Medicaid_capita, Total_medicaid_cap, Medicaid_budget_state )\n",
    "\n",
    "# Proportional allocation according to last 14 days positive COVID cases in each county\n",
    "Proportional_to_covid = Proportional_allocation(COVID_14days, Covid_state, Medicaid_budget_state)\n",
    "\n",
    "# Proportional allocation according to SVI score in each county\n",
    "Proportional_to_SVI = Proportional_allocation(SVI_county, SVI_state, Medicaid_budget_state)\n",
    "\n",
    "# Proportional allocation according to YPLL in each county\n",
    "Proportional_to_YPLL = Proportional_allocation(YPLL, YPLL_state, Medicaid_budget_state)\n",
    "\n",
    "# Proportional allocation according to Unemployment  in each county\n",
    "Proportional_to_unemployment = Proportional_allocation(Unemployment, Unemployment_state, Medicaid_budget_state)\n",
    "\n",
    "# Proportional allocation according to Medicaid enrolles per capita in each county\n",
    "Proportional_to_unemployment_cap = Proportional_allocation(Unemployment_capita, Total_unemployment_cap, Medicaid_budget_state )\n",
    "\n",
    "# Proportional allocation according to last 14 days positive COVID cases per capita in each county\n",
    "Proportional_to_covid_capita = Proportional_allocation(Covid_capita, Total_covid_cap, Medicaid_budget_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize values for comparison\n",
    "To be able compare the different vulnerability values for each county, we normalize all vulnerability values as follows. \n",
    "\n",
    "Let $m_{v_s} = \\min \\{v_j, \\text{ for county j in state s }\\}$  and \n",
    "$M_{v_s} = \\max \\{v_j, \\text{ for county j in state s }\\}$.\n",
    "\n",
    "We calculate the normalize value for each vulnerability for each county by substracting the min vulnerability in the state of the county and dividing that by the differences between max and min value of the vulnerability values in the state. Mathematical formulation for the normalization is as follows.\n",
    "\n",
    "$N_{v_j} = \\frac{v_j - m_{v_s}}{M_{v_s} - m_{v_s}}$ \n",
    "\n",
    "for each $v \\in V$, where V = {Medicaid, SVI, YPLL, Unemployment, COVID, COVID_capita, COVID_death and COVID_death capita, SVI and Medicaid, YPLL and Medicaid, Unemployment and Medicaid, COVID and Medicaid, COVID_capita and Medicaid, COVID_death and Medicaid and COVID_death capita and Medicaid}, j is a county in each state $s \\in S$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize function to normalize the vulnerability values to be able to compare them\n",
    "\n",
    "def normalize(dict_1):\n",
    "    \n",
    "    result = {}\n",
    "    min_data = {s: min(dict_1[j] for j in location if (j,s) in cartesian_pro_county_state) for s in State }\n",
    "    max_data = {s: max(dict_1[j] for j in location if (j,s) in cartesian_pro_county_state) for s in State }\n",
    "    \n",
    "    for (j,s) in cartesian_pro_county_state:\n",
    "        \n",
    "        if (max_data[s] - min_data[s]) != 0 :\n",
    "    \n",
    "            result[j] = (dict_1[j] - min_data[s])/(max_data[s] - min_data[s])\n",
    "        \n",
    "        else:\n",
    "            result[j] = 1\n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentile Rank\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.percentileofscore.html\"> The function scipy.stats.percentileofscore (a, score, kind='rank')   </a>\n",
    "computes the percentile rank of a score relative to a list of scores. \n",
    "\"rank\": Average percentage ranking of score. In case of multiple matches, average the percentage rankings of all matching scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate percentile ranks\n",
    "\n",
    "def percentile_ranks(data):\n",
    "    \n",
    "    x = [*data.values()]\n",
    "    \n",
    "    percentile_ranks = {i: stats.percentileofscore(x, data[i], 'rank') for i in data}\n",
    "\n",
    "    return percentile_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write timestamp \n",
    "\n",
    "time_stamp = time.strftime('%m-%d-%Y %H:%M:%S')\n",
    "with open('Output/time_stamp.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    now = time.strftime('%m/%d/%Y %H:%M:%S')\n",
    "    w.writerow(['time',now])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file allocation with each strategies for each county \n",
    "\n",
    "Strategies = [\"Medicaid_demand\", \"Medicaid_capita\", \"Covid\", \"SVI\"\n",
    "              , \"YPLL\",\"Unemployment\", \"Unemployment_capita\", \"Covid_capita\",  \"Covid_death_capita\" ]\n",
    "\n",
    "fieldnames = []  \n",
    "fieldnames.append('County_FIPS')\n",
    "\n",
    "\n",
    "SVI_values = {i:SVI_county[i] for i in location}\n",
    "s_count = 1\n",
    "for s in Strategies:   \n",
    "    fieldnames.append('Proportional_allocation_to_' + s)\n",
    "    fieldnames.append(s)\n",
    "    fieldnames.append('Percentile_ranks_' + s)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "writefile = 'Output/County_level_proportional_allocation_for_all_policies.csv'\n",
    "with open( writefile, 'w' ) as f:\n",
    "    writer = csv.writer(f)                \n",
    "    writer.writerow(fieldnames)\n",
    "    for row in zip(location\n",
    "                   , Proportional_to_medicaid.values(),         Medicaid_demand.values(),      percentile_ranks(Medicaid_demand).values()\n",
    "                   , Proportional_to_medicaid_cap.values(),     Medicaid_capita.values(),      percentile_ranks(Medicaid_capita).values()\n",
    "                   , Proportional_to_covid.values(),            COVID_14days.values(),         percentile_ranks(COVID_14days).values()\n",
    "                   , Proportional_to_SVI.values(),              SVI_county.values(),           percentile_ranks(SVI_county).values()\n",
    "                   , Proportional_to_YPLL.values(),             YPLL.values(),                 percentile_ranks(YPLL).values()\n",
    "                   , Proportional_to_unemployment.values(),     Unemployment.values(),         percentile_ranks(Unemployment).values()\n",
    "                   , Proportional_to_unemployment_cap.values(), Unemployment_capita.values(),  percentile_ranks(Unemployment_capita).values()\n",
    "                   , Proportional_to_covid_capita.values(),     Covid_capita.values(),         percentile_ranks(Covid_capita).values()\n",
    "                   , Proportional_to_covid_death_cap.values(),  Covid_death_capita.values(),   percentile_ranks(Covid_death_capita).values() ):                    \n",
    "       \n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
